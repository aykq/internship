{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNb8zBCMkOXH7gEl5e5ZXGk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aykq/internship/blob/main/tensorflow/03_Transfer_Learning_with_TensorFlow_Part_1_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow Part 1: Feature Extraction"
      ],
      "metadata": {
        "id": "8MDfiWvoyiy_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've built a bunch of convolutional neural networks from scratch and they all seem to be learning, however, there is still plenty of room for improvement.\n",
        "\n",
        "To improve our model(s), we could spend a while trying different configurations, adding more layers, changing the learning rate, adjusting the number of neurons per layer and more.\n",
        "\n",
        "However, doing this is very time consuming.\n",
        "\n",
        "Luckily, there's a technique we can use to save time.\n",
        "\n",
        "It's called **transfer learning**, in other words, taking the patters (also called weights) another model has learned from another problem and using them for our own problem.\n",
        "\n",
        "There are two main benefits to using transfer learning:\n",
        "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
        "2. Can leverage a working neural network architecture which has **already learned** patterns on similar data to our own. This often results in achieving great results with less custom data.\n",
        "\n",
        "What this means is, instead of hand-crafting our own neural network architectures or building them from scratch, we can utilise models which have worked for others.\n",
        "\n",
        "And instead of training our own models from scratch on our own datasets, we can take the patterns a model has learned from datasets such as [ImageNet](http://www.image-net.org/) (millions of images of different objects) and use them as the foundation of our own. Doing this often leads to getting great results with less data.\n",
        "\n",
        "Over the next few notebooks, we'll see the power of transfer learning in action."
      ],
      "metadata": {
        "id": "vbLYgICWyowY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# What we're going to cover\n",
        "\n",
        "We're going to go through the following with TensorFlow:\n",
        "\n",
        "+ Introduce transfer learning (a way to beat all of our old self-built models)\n",
        "+ Using a smaller dataset to experiment faster (10% of training samples of 10 classes of food)\n",
        "+ Build a transfer learning feature extraction model using TensorFlow Hub\n",
        "+ Introduce the TensorBoard callback to track model training results\n",
        "+ Compare model results using TensorBoard\n"
      ],
      "metadata": {
        "id": "1OX56LhnzuWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Using a GPU\n",
        "\n",
        "To begin, let's check to see if we're using a GPU. Using a GPU will make sure our model trains faster than using just a CPU."
      ],
      "metadata": {
        "id": "lmZsoopBz4kI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j1BRpw1yY6L",
        "outputId": "b02b30c9-7cf6-426f-b561-07186132d468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul 18 07:16:43 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# are we using gpu\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the cell above doesn't output something which looks like:\n",
        "\n",
        "```+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
        "|                               |                      |                 ERR! |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "\n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```\n",
        "\n",
        "Go to Runtime -> Change Runtime Type -> Hardware Accelerator and select \"GPU\", then rerun the cell above.\n"
      ],
      "metadata": {
        "id": "KVpbhd_B0azn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Transfer learning with TensorFlow Hub: Getting great results with 10% of the data\n",
        "\n",
        "If you've been thinking, \"surely someone else has spent the time crafting the right model for the job...\" then you're in luck.\n",
        "\n",
        "For many of the problems you'll want to use deep learning for, chances are, a working model already exists.\n",
        "\n",
        "And the good news is, you can access many of them on TensorFlow Hub.\n",
        "\n",
        "[TensorFlow Hub](https://tfhub.dev/) is a repository for existing model components. It makes it so you can import and use a fully trained model with as little as a URL.\n",
        "\n",
        "Now, I really want to demonstrate the power of transfer learning to you.\n",
        "\n",
        "To do so, what if I told you we could get much of the same results (or better) than our best model has gotten so far with only 10% of the original data, in other words, 10x less data.\n",
        "\n",
        "This seems counterintuitive right?\n",
        "\n",
        "Wouldn't you think more examples of what a picture of food looked like led to better results?\n",
        "\n",
        "And you'd be right if you thought so, generally, more data leads to better results.\n",
        "\n",
        "However, what if you didn't have more data? What if instead of 750 images per class, you had 75 images per class?\n",
        "\n",
        "Collecting 675 more images of a certain class could take a long time.\n",
        "\n",
        "**Transfer learning often allows you to get great results with less data.**\n",
        "\n",
        "But don't just take my word for it. Let's download a subset of the data we've been using, namely 10% of  the training data from the `10_food_classe` dataset and use it to train a food image classifier on."
      ],
      "metadata": {
        "id": "DBfd7NfF1foN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-transfer-learning-feature-extraction.png)\n",
        "\n",
        "What we're working towards building. Taking a pre-trained model and adding our own custom layers on top, extracting all of the underlying patterns learned on another dataset our own images."
      ],
      "metadata": {
        "id": "mBByLGWJ2DiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Downlading and becoming one with the data"
      ],
      "metadata": {
        "id": "m0rbZ1Ww2sHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get data (10% of labels)\n",
        "import zipfile\n",
        "\n",
        "# download data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUKgMgPp2xew",
        "outputId": "e128447d-baed-401c-a160-2ac40d18f541"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-18 07:16:43--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.201.128, 74.125.202.128, 74.125.69.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.201.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   231MB/s    in 0.7s    \n",
            "\n",
            "2023-07-18 07:16:44 (231 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many images in each folder?\n",
        "import os\n",
        "\n",
        "# walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TwUAzZY2-wU",
        "outputId": "b502f234-c34f-4700-cb50-286a0f659352"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how each of the training directories now has 75 images rather than 750 images. This is key to demonstrating how well transfer learning can perform with less labelled images.\n",
        "\n",
        "The test directories still have the same amount of images. This means we'll be training on less data but evaluating our models on the same amount of test data.\n"
      ],
      "metadata": {
        "id": "EZzFJg0f3CyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Creating data loaders (preparing the data)\n",
        "\n",
        "Now we've downloaded the data, let's use the `ImageDataGenerator` class along with the `flow_from_directory` method to load in our images."
      ],
      "metadata": {
        "id": "_m6WtL7a3Isz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=IMAGE_SHAPE,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "print(\"Testing images:\")\n",
        "test_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                              target_size=IMAGE_SHAPE,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "cgu-NSBB3V_2",
        "outputId": "76e64280-f336-42a7-99f0-b437a6ef44a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading in the data we can see we've got 750 images in the training dataset belonging to 10 classes (75 per class) and 2500 images in the test set belonging to 10 classes (250 per class)."
      ],
      "metadata": {
        "id": "OYID3dYC3ayg"
      }
    }
  ]
}